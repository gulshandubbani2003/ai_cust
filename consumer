package com.jobreadyprogrammer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;
import com.mongodb.client.MongoClient;
import com.mongodb.client.MongoClients;
import com.mongodb.client.MongoCollection;
import org.bson.Document;
import com.fasterxml.jackson.databind.ObjectMapper;

import java.util.Base64;
import java.util.Collections;
import java.util.Map;
import java.util.Properties;

public class KafkaConsumerExample {
    private static final String BOOTSTRAP_SERVERS = "localhost:9092";
    private static final String TOPIC = "elevenlabs-topic";
    private static final String MONGO_URI = "mongodb://localhost:27017";

    public static void consumeAndStore() {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "elevenlabs-consumer-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 10);  // Limit number of records per poll

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList(TOPIC));

        ObjectMapper mapper = new ObjectMapper();

        try (MongoClient mongoClient = MongoClients.create(MONGO_URI)) {
            MongoCollection<Document> collection = mongoClient.getDatabase("elevenlabs_db")
                    .getCollection("audio_data");

            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(java.time.Duration.ofMillis(1000));
                
                if (!records.isEmpty()) {
                    System.out.println("Received " + records.count() + " records");
                }

                for (ConsumerRecord<String, String> record : records) {
                    try {
                        // Detailed logging
                        System.out.println("Consumed Record:");
                        System.out.println("Topic: " + record.topic());
                        System.out.println("Partition: " + record.partition());
                        System.out.println("Offset: " + record.offset());
                        System.out.println("Timestamp: " + record.timestamp());
                        System.out.println("Message: " + record.value());

                        // Parse the JSON message
                        Map<String, Object> message = mapper.readValue(record.value(), Map.class);
                        
                        // Decode and print audio data length
                        String base64Data = (String) message.get("audio_data");
                        byte[] audioBytes = Base64.getDecoder().decode(base64Data);
                        System.out.println("Audio Data Length: " + audioBytes.length + " bytes");

                        // Convert back to a format suitable for MongoDB
                        Document doc = new Document(message);
                        collection.insertOne(doc);
                        
                        System.out.println("Document inserted into MongoDB");
                    } catch (Exception e) {
                        System.err.println("Error processing record: " + e.getMessage());
                        e.printStackTrace();
                    }
                }
            }
        } catch (Exception e) {
            System.err.println("Consumer Error: " + e.getMessage());
            e.printStackTrace();
        } finally {
            consumer.close();
        }
    }

    public static void main(String[] args) {
        consumeAndStore();
    }
}
